{"cells":[{"cell_type":"markdown","source":["## PySpark JSON Functions\n\nPySpark JSON functions are used to query or extract the elements from JSON string of DataFrame column by path, convert it to struct, map type e.t.c.\n\n`from_json()` – Converts JSON string into Struct type or Map type.  \n`to_json()` – Converts MapType or Struct type to JSON string.  \n`json_tuple()` – Extract the Data from JSON and create them as a new columns.  \n`get_json_object()` – Extracts JSON element from a JSON string based on json path specified.  \n`schema_of_json()` – Create schema string from JSON string."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5d9fc83-b223-4022-add7-37433a769f59"}}},{"cell_type":"code","source":["dbutils.library.restartPython() # Removes Python state, but some libraries might not work without calling this command.dbutils.restartPython()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f4dac6b-ee25-4716-8e80-d1257d300e56"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Load libraries"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a280b9b-00d3-45a7-ab54-f88a7376e037"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession, Row\nfrom pyspark.sql.types import IntegerType, DateType, StringType, StructType, StructField, ArrayType, MapType, DoubleType, MapType\nfrom pyspark.sql.functions import lit, col, expr, when, sum, avg, max, min, mean, count, from_json, to_json, json_tuple, get_json_object, schema_of_json"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e0d5fac-1ce1-4733-9bc0-4f9cc891d982"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Create Spark session"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbed0d19-71c5-4c1b-8340-d6c6ca5d9083"}}},{"cell_type":"code","source":["spark = SparkSession.builder.appName('PySpark JSON Functions').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"654acd8e-adfb-4f22-94dd-d826125ee9ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["jsonString = \"\"\"{\"Zipcode\":704,\"ZipCodeType\":\"STANDARD\",\"City\":\"PARC PARQUE\",\"State\":\"PR\"}\"\"\"\ndf = spark.createDataFrame([(1, jsonString)],[\"id\",\"value\"])\ndf.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e6112c8-87a7-4e14-b096-c61d4e48b80c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"value","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+---+--------------------------------------------------------------------------+\n|id |value                                                                     |\n+---+--------------------------------------------------------------------------+\n|1  |{&#34;Zipcode&#34;:704,&#34;ZipCodeType&#34;:&#34;STANDARD&#34;,&#34;City&#34;:&#34;PARC PARQUE&#34;,&#34;State&#34;:&#34;PR&#34;}|\n+---+--------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+--------------------------------------------------------------------------+\nid |value                                                                     |\n+---+--------------------------------------------------------------------------+\n1  |{&#34;Zipcode&#34;:704,&#34;ZipCodeType&#34;:&#34;STANDARD&#34;,&#34;City&#34;:&#34;PARC PARQUE&#34;,&#34;State&#34;:&#34;PR&#34;}|\n+---+--------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### from_json()\n\nConverts JSON string into Struct type or Map type"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2bb72582-8e32-40ff-883a-81087fd1d0fc"}}},{"cell_type":"code","source":["df2=df.withColumn('value',from_json(df.value,MapType(StringType(),StringType())))\ndf2.printSchema()\ndf2.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25dec94e-69ba-432e-86c2-6d2fd3660306"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df2","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"value","nullable":true,"type":{"keyType":"string","type":"map","valueContainsNull":true,"valueType":"string"}}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- id: long (nullable = true)\n |-- value: map (nullable = true)\n |    |-- key: string\n |    |-- value: string (valueContainsNull = true)\n\n+---+---------------------------------------------------------------------------+\n|id |value                                                                      |\n+---+---------------------------------------------------------------------------+\n|1  |[Zipcode -&gt; 704, ZipCodeType -&gt; STANDARD, City -&gt; PARC PARQUE, State -&gt; PR]|\n+---+---------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: long (nullable = true)\n-- value: map (nullable = true)\n    |-- key: string\n    |-- value: string (valueContainsNull = true)\n\n+---+---------------------------------------------------------------------------+\nid |value                                                                      |\n+---+---------------------------------------------------------------------------+\n1  |[Zipcode -&gt; 704, ZipCodeType -&gt; STANDARD, City -&gt; PARC PARQUE, State -&gt; PR]|\n+---+---------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### to_json()\n\nConverts DataFrame columns MapType or Struct type to JSON string"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5a65aca5-3975-433b-8709-9d0748a98600"}}},{"cell_type":"code","source":["df3 = df2.withColumn('value',to_json(col('value')))\ndf3.printSchema()\ndf3.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"9b87b2b8-0c41-4af4-b13a-ba4ca9a5d91f"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df3","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"value","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- id: long (nullable = true)\n |-- value: string (nullable = true)\n\n+---+----------------------------------------------------------------------------+\n|id |value                                                                       |\n+---+----------------------------------------------------------------------------+\n|1  |{&#34;Zipcode&#34;:&#34;704&#34;,&#34;ZipCodeType&#34;:&#34;STANDARD&#34;,&#34;City&#34;:&#34;PARC PARQUE&#34;,&#34;State&#34;:&#34;PR&#34;}|\n+---+----------------------------------------------------------------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: long (nullable = true)\n-- value: string (nullable = true)\n\n+---+----------------------------------------------------------------------------+\nid |value                                                                       |\n+---+----------------------------------------------------------------------------+\n1  |{&#34;Zipcode&#34;:&#34;704&#34;,&#34;ZipCodeType&#34;:&#34;STANDARD&#34;,&#34;City&#34;:&#34;PARC PARQUE&#34;,&#34;State&#34;:&#34;PR&#34;}|\n+---+----------------------------------------------------------------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### json_tuple()\n\nIs used the query or extract the elements from JSON column and create the result as a new columns."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"77b810ab-a072-4011-b8df-6b1866df7312"}}},{"cell_type":"code","source":["df4 = (\n  df.select(\n    col('id'),\n    json_tuple(col('value'),'Zipcode','ZipCodeType','City','State')\n  )\n  .toDF('id','Zipcode','ZipCodeType','City','State')\n)\ndf4.printSchema()\ndf4.show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3efb683a-15d9-48cf-996a-85881607fbd7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df4","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"id","nullable":true,"type":"long"},{"metadata":{},"name":"Zipcode","nullable":true,"type":"string"},{"metadata":{},"name":"ZipCodeType","nullable":true,"type":"string"},{"metadata":{},"name":"City","nullable":true,"type":"string"},{"metadata":{},"name":"State","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">root\n |-- id: long (nullable = true)\n |-- Zipcode: string (nullable = true)\n |-- ZipCodeType: string (nullable = true)\n |-- City: string (nullable = true)\n |-- State: string (nullable = true)\n\n+---+-------+-----------+-----------+-----+\n|id |Zipcode|ZipCodeType|City       |State|\n+---+-------+-----------+-----------+-----+\n|1  |704    |STANDARD   |PARC PARQUE|PR   |\n+---+-------+-----------+-----------+-----+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">root\n-- id: long (nullable = true)\n-- Zipcode: string (nullable = true)\n-- ZipCodeType: string (nullable = true)\n-- City: string (nullable = true)\n-- State: string (nullable = true)\n\n+---+-------+-----------+-----------+-----+\nid |Zipcode|ZipCodeType|City       |State|\n+---+-------+-----------+-----------+-----+\n1  |704    |STANDARD   |PARC PARQUE|PR   |\n+---+-------+-----------+-----------+-----+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### get_json_object()\n\nIs used to extract the JSON string based on path from the JSON column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"674ba216-8f6e-4eed-8fb9-6429ed83691e"}}},{"cell_type":"code","source":["df.select(\n  col('id'),\n  get_json_object(col('value'),'$.ZipCodeType').alias('ZipCodeType')\n).show(truncate=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a46e9da6-22fd-474c-8419-eda1b74db235"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+---+-----------+\n|id |ZipCodeType|\n+---+-----------+\n|1  |STANDARD   |\n+---+-----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+---+-----------+\nid |ZipCodeType|\n+---+-----------+\n1  |STANDARD   |\n+---+-----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### schema_of_json() \n\nIs used to create schema string from JSON string column."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0fa2eadc-833a-4705-982a-23893cf6e8a7"}}},{"cell_type":"code","source":["# spaek.range(start,end,step,numSlices) - Creates a new RDD of int containing elements from start to end (exclusive), \n# increased by step every element. Can be called the same way as python’s built-in range() function. \n# If called with a single argument, the argument is interpreted as end, and start is set to 0.\n\nschemaStr = spark.range(1).select(schema_of_json(lit(jsonString))).collect()[0][0]\nprint(schemaStr)"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"da16c343-d72a-410e-8539-b9032f5205b9"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">struct&lt;City:string,State:string,ZipCodeType:string,Zipcode:bigint&gt;\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">struct&lt;City:string,State:string,ZipCodeType:string,Zipcode:bigint&gt;\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### The end of the notebook"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6812f029-60e8-4912-9339-cdbcc67079df"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"json","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":210159929638161}},"nbformat":4,"nbformat_minor":0}

{"cells":[{"cell_type":"markdown","source":["## PySpark UDF (User Defined Function)\n\nIn PySpark, you can create a function and wrap it with PySpark SQL `udf()` or register it as UDF and use it on DataFrame and SQl respectively.\nUDF’s are the most expensive operations hence use them only you have no choice and when essential."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"b5d9fc83-b223-4022-add7-37433a769f59"}}},{"cell_type":"code","source":["dbutils.library.restartPython() # Removes Python state, but some libraries might not work without calling this command.dbutils.restartPython()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7f4dac6b-ee25-4716-8e80-d1257d300e56"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Load libraries"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a280b9b-00d3-45a7-ab54-f88a7376e037"}}},{"cell_type":"code","source":["from pyspark.sql import SparkSession, Row\nfrom pyspark.sql.types import IntegerType, DateType, StringType, StructType, StructField, ArrayType, MapType, DoubleType\nfrom pyspark.sql.functions import lit, col, expr, when, sum, avg, max, min, mean, count, udf"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2e0d5fac-1ce1-4733-9bc0-4f9cc891d982"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Create Spark session"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"dbed0d19-71c5-4c1b-8340-d6c6ca5d9083"}}},{"cell_type":"code","source":["spark = SparkSession.builder.appName('PySpark UDF (User Defined Function)').getOrCreate()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"654acd8e-adfb-4f22-94dd-d826125ee9ad"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Create a DataFrame"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"de77f996-0393-4722-95d6-eeaf1edefb04"}}},{"cell_type":"code","source":["columns = ['seqno','name']\n\ndata = [\n  ('1', 'john jones'),\n  ('2', 'tracey smith'),\n  ('3', 'amy sanders')\n]\n\ndf = spark.createDataFrame(data=data,schema=columns)\n\ndf.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"1e6112c8-87a7-4e14-b096-c61d4e48b80c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"seqno","nullable":true,"type":"string"},{"metadata":{},"name":"name","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+-----+------------+\n|seqno|        name|\n+-----+------------+\n|    1|  john jones|\n|    2|tracey smith|\n|    3| amy sanders|\n+-----+------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------+\nseqno|        name|\n+-----+------------+\n    1|  john jones|\n    2|tracey smith|\n    3| amy sanders|\n+-----+------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Create a Python Function"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2bb72582-8e32-40ff-883a-81087fd1d0fc"}}},{"cell_type":"code","source":["def convertCase(str):\n  resStr = ''\n  arr = str.split(' ')\n  for x in arr:\n     resStr = f'{resStr}{x[0:1].upper()}{x[1:len(x)]} '\n  return resStr.strip()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"25dec94e-69ba-432e-86c2-6d2fd3660306"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Convert a Python function to PySpark UDF\n\nNow convert this function `convertCase()` to UDF by passing the function to PySpark SQL `udf()`.  \nThis function is available at `org.apache.spark.sql.functions.udf` package. Make sure you import this package before using it."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"32b06981-5139-4c13-bdc2-e9ba29282468"}}},{"cell_type":"code","source":["# Converting function to UDF\nconvertUDF = udf(lambda z: convertCase(z),StringType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"f4f2b5db-5791-410a-8679-8e7d5e4b003c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"code","source":["# Converting function to UDF StringType() is by default hence not required\nconvertUDF = udf(lambda z: convertCase(z))"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"d935f4ef-15ec-4881-806e-5b7697ff2d35"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Using UDF with DataFrame | select()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c290baad-d47f-484a-b062-c7dcce82623b"}}},{"cell_type":"code","source":["df.select(\n  col('seqno'),\n  convertUDF(col('name')).alias('name')\n).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"fc399240-c958-40a0-95a1-ad8746f9c65c"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+------------+\n|seqno|        name|\n+-----+------------+\n|    1|  John Jones|\n|    2|Tracey Smith|\n|    3| Amy Sanders|\n+-----+------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------+\nseqno|        name|\n+-----+------------+\n    1|  John Jones|\n    2|Tracey Smith|\n    3| Amy Sanders|\n+-----+------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Using UDF with DataFrame | withColumn()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"beb9ca04-bfc7-484b-93b9-9372c3bb0b87"}}},{"cell_type":"code","source":["df.withColumn('fixed_name', convertUDF(col('name'))).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e39cea48-cad7-4b0c-8d1d-7a2a8f308146"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+------------+------------+\n|seqno|        name|  fixed_name|\n+-----+------------+------------+\n|    1|  john jones|  John Jones|\n|    2|tracey smith|Tracey Smith|\n|    3| amy sanders| Amy Sanders|\n+-----+------------+------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------+------------+\nseqno|        name|  fixed_name|\n+-----+------------+------------+\n    1|  john jones|  John Jones|\n    2|tracey smith|Tracey Smith|\n    3| amy sanders| Amy Sanders|\n+-----+------------+------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Registering PySpark UDF & use it on SQL"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"2b1e851e-f746-43f3-a94a-5009850ca8bd"}}},{"cell_type":"code","source":["spark.udf.register('convertUDF', convertCase, StringType())\n\ndf.createOrReplaceTempView('seq_tbl')\n\nspark.sql('select seqno, convertUDF(name) as name from seq_tbl').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"a97df88c-ee4b-4e27-af2c-79d8edb6ce01"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+------------+\n|seqno|        name|\n+-----+------------+\n|    1|  John Jones|\n|    2|Tracey Smith|\n|    3| Amy Sanders|\n+-----+------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------+\nseqno|        name|\n+-----+------------+\n    1|  John Jones|\n    2|Tracey Smith|\n    3| Amy Sanders|\n+-----+------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Creating UDF using annotation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"c47397af-f5df-4302-a334-5891c8164038"}}},{"cell_type":"code","source":["@udf(returnType = StringType()) \ndef upperCase(str):\n  return str.upper()\n\ndf.withColumn('CAPS name', upperCase(col('name'))).show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"8f97c6bd-9c58-4d40-9791-579f79decff0"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+------------+------------+\n|seqno|        name|   CAPS name|\n+-----+------------+------------+\n|    1|  john jones|  JOHN JONES|\n|    2|tracey smith|TRACEY SMITH|\n|    3| amy sanders| AMY SANDERS|\n+-----+------------+------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------+------------+\nseqno|        name|   CAPS name|\n+-----+------------+------------+\n    1|  john jones|  JOHN JONES|\n    2|tracey smith|TRACEY SMITH|\n    3| amy sanders| AMY SANDERS|\n+-----+------------+------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### Special Handling"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"7b0c28d9-1476-46e2-8a3f-05e3b9fefb75"}}},{"cell_type":"markdown","source":["PySpark/Spark does not guarantee the order of evaluation of subexpressions meaning expressions are not guarantee to evaluated left-to-right or in any other fixed order.  \nPySpark reorders the execution for query optimization and planning hence, AND, OR, WHERE and HAVING expression will have side effects.  \nWhen you are designing and using UDF, you have to be very careful especially with null handling as these results runtime exceptions."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e3ac1fe7-5de6-45ca-bf85-e0b5723fc225"}}},{"cell_type":"markdown","source":["##### Execution order"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ffd410f3-1317-4cfe-a287-7a58c99ffddf"}}},{"cell_type":"code","source":["# No guarantee Name is not null will execute first\n# If convertUDF(Name) like '%John%' execute first then \n# you will get runtime error\n\nspark.sql(\"\"\"\nselect seqno, \n       convertUDF(name) as name \nfrom seq_tbl \nwhere name is not null and convertUDF(name) like '%John%'\n\"\"\").show()  "],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"ada78c0e-7d4f-4980-8039-aa4a341778dd"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+----------+\n|seqno|      name|\n+-----+----------+\n|    1|John Jones|\n+-----+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----------+\nseqno|      name|\n+-----+----------+\n    1|John Jones|\n+-----+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["##### Handling null check"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"4a691e45-833d-4cf6-ad73-fdbe76897b6d"}}},{"cell_type":"code","source":["columns = ['seqno','name']\n\ndata = [\n  ('1', 'john jones'),\n  ('2', 'tracey smith'),\n  ('3', 'amy sanders'),\n  ('4', None)\n]\n\ndf2 = spark.createDataFrame(data=data,schema=columns)\n\ndf2.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"e35f7cb2-01bf-47f8-8de5-f2f5bd028fb2"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[{"name":"df2","typeStr":"pyspark.sql.dataframe.DataFrame","schema":{"fields":[{"metadata":{},"name":"seqno","nullable":true,"type":"string"},{"metadata":{},"name":"name","nullable":true,"type":"string"}],"type":"struct"},"tableIdentifier":null}],"data":"<div class=\"ansiout\">+-----+------------+\n|seqno|        name|\n+-----+------------+\n|    1|  john jones|\n|    2|tracey smith|\n|    3| amy sanders|\n|    4|        null|\n+-----+------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+------------+\nseqno|        name|\n+-----+------------+\n    1|  john jones|\n    2|tracey smith|\n    3| amy sanders|\n    4|        null|\n+-----+------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["df2.createOrReplaceTempView('seq_tbl2')\nspark.sql(\"select convertUDF(name) from seq_tbl2\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0c6bffe1-70d5-4822-a98a-e43e9886c968"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}},{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"data":"<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">PythonException</span>                           Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4297364997129045&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> df2<span class=\"ansi-blue-fg\">.</span>createOrReplaceTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;seq_tbl2&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;select convertUDF(name) from seq_tbl2&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span>truncate<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">show</span><span class=\"ansi-blue-fg\">(self, n, truncate, vertical)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>             print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>showString<span class=\"ansi-blue-fg\">(</span>n<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">20</span><span class=\"ansi-blue-fg\">,</span> vertical<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 443</span><span class=\"ansi-red-fg\">             </span>print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>showString<span class=\"ansi-blue-fg\">(</span>n<span class=\"ansi-blue-fg\">,</span> int<span class=\"ansi-blue-fg\">(</span>truncate<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> vertical<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    444</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    445</span>     <span class=\"ansi-green-fg\">def</span> __repr__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n\n<span class=\"ansi-red-fg\">PythonException</span>: An exception was thrown from a UDF: &#39;AttributeError: &#39;NoneType&#39; object has no attribute &#39;split&#39;&#39;, from &lt;command-4297364997129036&gt;, line 3. Full traceback below:\nTraceback (most recent call last):\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 654, in main\n    process()\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 646, in process\n    serializer.dump_stream(out_iter, outfile)\n  File &#34;/databricks/spark/python/pyspark/serializers.py&#34;, line 231, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File &#34;/databricks/spark/python/pyspark/serializers.py&#34;, line 145, in dump_stream\n    for obj in iterator:\n  File &#34;/databricks/spark/python/pyspark/serializers.py&#34;, line 220, in _batched\n    for item in iterator:\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 467, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 467, in &lt;genexpr&gt;\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 91, in &lt;lambda&gt;\n    return lambda *a: f(*a)\n  File &#34;/databricks/spark/python/pyspark/util.py&#34;, line 109, in wrapper\n    return f(*args, **kwargs)\n  File &#34;&lt;command-4297364997129036&gt;&#34;, line 3, in convertCase\nAttributeError: &#39;NoneType&#39; object has no attribute &#39;split&#39;\n</div>","errorSummary":"<span class=\"ansi-red-fg\">PythonException</span>: An exception was thrown from a UDF: &#39;AttributeError: &#39;NoneType&#39; object has no attribute &#39;split&#39;&#39;, from &lt;command-4297364997129036&gt;, line 3. Full traceback below:","metadata":{},"errorTraceType":"html","type":"ipynbError","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"><span class=\"ansi-red-fg\">---------------------------------------------------------------------------</span>\n<span class=\"ansi-red-fg\">PythonException</span>                           Traceback (most recent call last)\n<span class=\"ansi-green-fg\">&lt;command-4297364997129045&gt;</span> in <span class=\"ansi-cyan-fg\">&lt;module&gt;</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">      1</span> df2<span class=\"ansi-blue-fg\">.</span>createOrReplaceTempView<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#39;seq_tbl2&#39;</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-fg\">----&gt; 2</span><span class=\"ansi-red-fg\"> </span>spark<span class=\"ansi-blue-fg\">.</span>sql<span class=\"ansi-blue-fg\">(</span><span class=\"ansi-blue-fg\">&#34;select convertUDF(name) from seq_tbl2&#34;</span><span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">.</span>show<span class=\"ansi-blue-fg\">(</span>truncate<span class=\"ansi-blue-fg\">=</span><span class=\"ansi-green-fg\">False</span><span class=\"ansi-blue-fg\">)</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/dataframe.py</span> in <span class=\"ansi-cyan-fg\">show</span><span class=\"ansi-blue-fg\">(self, n, truncate, vertical)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    441</span>             print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>showString<span class=\"ansi-blue-fg\">(</span>n<span class=\"ansi-blue-fg\">,</span> <span class=\"ansi-cyan-fg\">20</span><span class=\"ansi-blue-fg\">,</span> vertical<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    442</span>         <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-fg\">--&gt; 443</span><span class=\"ansi-red-fg\">             </span>print<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">.</span>_jdf<span class=\"ansi-blue-fg\">.</span>showString<span class=\"ansi-blue-fg\">(</span>n<span class=\"ansi-blue-fg\">,</span> int<span class=\"ansi-blue-fg\">(</span>truncate<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">,</span> vertical<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    444</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">    445</span>     <span class=\"ansi-green-fg\">def</span> __repr__<span class=\"ansi-blue-fg\">(</span>self<span class=\"ansi-blue-fg\">)</span><span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py</span> in <span class=\"ansi-cyan-fg\">__call__</span><span class=\"ansi-blue-fg\">(self, *args)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1303</span>         answer <span class=\"ansi-blue-fg\">=</span> self<span class=\"ansi-blue-fg\">.</span>gateway_client<span class=\"ansi-blue-fg\">.</span>send_command<span class=\"ansi-blue-fg\">(</span>command<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">   1304</span>         return_value = get_return_value(\n<span class=\"ansi-green-fg\">-&gt; 1305</span><span class=\"ansi-red-fg\">             answer, self.gateway_client, self.target_id, self.name)\n</span><span class=\"ansi-green-intense-fg ansi-bold\">   1306</span> \n<span class=\"ansi-green-intense-fg ansi-bold\">   1307</span>         <span class=\"ansi-green-fg\">for</span> temp_arg <span class=\"ansi-green-fg\">in</span> temp_args<span class=\"ansi-blue-fg\">:</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">deco</span><span class=\"ansi-blue-fg\">(*a, **kw)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    131</span>                 <span class=\"ansi-red-fg\"># Hide where the exception came from that shows a non-Pythonic</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    132</span>                 <span class=\"ansi-red-fg\"># JVM exception message.</span>\n<span class=\"ansi-green-fg\">--&gt; 133</span><span class=\"ansi-red-fg\">                 </span>raise_from<span class=\"ansi-blue-fg\">(</span>converted<span class=\"ansi-blue-fg\">)</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    134</span>             <span class=\"ansi-green-fg\">else</span><span class=\"ansi-blue-fg\">:</span>\n<span class=\"ansi-green-intense-fg ansi-bold\">    135</span>                 <span class=\"ansi-green-fg\">raise</span>\n\n<span class=\"ansi-green-fg\">/databricks/spark/python/pyspark/sql/utils.py</span> in <span class=\"ansi-cyan-fg\">raise_from</span><span class=\"ansi-blue-fg\">(e)</span>\n\n<span class=\"ansi-red-fg\">PythonException</span>: An exception was thrown from a UDF: &#39;AttributeError: &#39;NoneType&#39; object has no attribute &#39;split&#39;&#39;, from &lt;command-4297364997129036&gt;, line 3. Full traceback below:\nTraceback (most recent call last):\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 654, in main\n    process()\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 646, in process\n    serializer.dump_stream(out_iter, outfile)\n  File &#34;/databricks/spark/python/pyspark/serializers.py&#34;, line 231, in dump_stream\n    self.serializer.dump_stream(self._batched(iterator), stream)\n  File &#34;/databricks/spark/python/pyspark/serializers.py&#34;, line 145, in dump_stream\n    for obj in iterator:\n  File &#34;/databricks/spark/python/pyspark/serializers.py&#34;, line 220, in _batched\n    for item in iterator:\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 467, in mapper\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 467, in &lt;genexpr&gt;\n    result = tuple(f(*[a[o] for o in arg_offsets]) for (arg_offsets, f) in udfs)\n  File &#34;/databricks/spark/python/pyspark/worker.py&#34;, line 91, in &lt;lambda&gt;\n    return lambda *a: f(*a)\n  File &#34;/databricks/spark/python/pyspark/util.py&#34;, line 109, in wrapper\n    return f(*args, **kwargs)\n  File &#34;&lt;command-4297364997129036&gt;&#34;, line 3, in convertCase\nAttributeError: &#39;NoneType&#39; object has no attribute &#39;split&#39;\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["It is always best practice to check for `null` inside a UDF function rather than checking for `null` outside.  \nIn any case, if you can’t do a null check in UDF at lease use `IF` or `CASE WHEN` to check for `null` and call UDF conditionally."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0ac56c6b-88b5-4712-8ef9-e57b54be6f52"}}},{"cell_type":"code","source":["spark.udf.register('_nullsafeUDF', lambda str: convertCase(str) if not str is None else '' , StringType())"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"af487aa8-fa7a-48bf-bda4-5b79dddb02ca"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">Out[15]: &lt;function __main__.&lt;lambda&gt;(str)&gt;</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">Out[15]: &lt;function __main__.&lt;lambda&gt;(str)&gt;</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql('select _nullsafeUDF(name) from seq_tbl2').show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"136db32f-36c4-4306-a48c-c10bf80600c5"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+------------------+\n|_nullsafeUDF(name)|\n+------------------+\n|        John Jones|\n|      Tracey Smith|\n|       Amy Sanders|\n|                  |\n+------------------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+------------------+\n_nullsafeUDF(name)|\n+------------------+\n        John Jones|\n      Tracey Smith|\n       Amy Sanders|\n                  |\n+------------------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"code","source":["spark.sql(\"\"\"select Seqno, _nullsafeUDF(name) as name from seq_tbl2 where name is not null and _nullsafeUDF(name) like '%John%'\"\"\").show()"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"3a6fe3cd-2349-41a4-ad2b-bbd1d593081b"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\">+-----+----------+\n|Seqno|      name|\n+-----+----------+\n|    1|John Jones|\n+-----+----------+\n\n</div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\">+-----+----------+\nSeqno|      name|\n+-----+----------+\n    1|John Jones|\n+-----+----------+\n\n</div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["#### The end of the notebook"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"6812f029-60e8-4912-9339-cdbcc67079df"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"18-user-defined-function-udf","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":4297364997129025}},"nbformat":4,"nbformat_minor":0}

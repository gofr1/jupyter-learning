{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python383jvsc74a57bd07e7ed898d369334e998bf643179707e62ca7f11d6a1140b26f2ba8bce3c4feca",
   "display_name": "Python 3.8.3 64-bit ('env-ml': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "7e7ed898d369334e998bf643179707e62ca7f11d6a1140b26f2ba8bce3c4feca"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# K-Nearest Neighbour Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "A supervised classifier that memorizes observations from within a test set to predict classification labels for new, unlabeled observations.\n",
    "\n",
    "KNN makes predictions based on how similar training observations are to the new, incoming observations.\n",
    "\n",
    "The more similar the observation values, the more likely they will be classified with the same label. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Use cases:\n",
    "\n",
    "- Stock Price Prediction\n",
    "- Credit Risk Analysis \n",
    "- Predictive Trip Planning\n",
    "- Recommendation Systems"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "Assumptions:\n",
    "\n",
    "- Dataset has little noise\n",
    "- Dataset is labeled\n",
    "- Dataset only contains relevant features\n",
    "- Dataset has distinguishable subgroups\n",
    "- Avoid using KNN on large datasets (it will take a long time)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import scipy\n",
    "import urllib\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt \n",
    "from pylab import rcParams\n",
    "\n",
    "from sklearn import neighbors, preprocessing, metrics\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=4, suppress=True)\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 7,4 \n",
    "plt.style.use('seaborn-whitegrid')"
   ]
  },
  {
   "source": [
    "## Importing your data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "               model   mpg  cyl   disp   hp  drat     wt   qsec  vs  am  gear  \\\n",
       "0          Mazda RX4  21.0    6  160.0  110  3.90  2.620  16.46   0   1     4   \n",
       "1      Mazda RX4 Wag  21.0    6  160.0  110  3.90  2.875  17.02   0   1     4   \n",
       "2         Datsun 710  22.8    4  108.0   93  3.85  2.320  18.61   1   1     4   \n",
       "3     Hornet 4 Drive  21.4    6  258.0  110  3.08  3.215  19.44   1   0     3   \n",
       "4  Hornet Sportabout  18.7    8  360.0  175  3.15  3.440  17.02   0   0     3   \n",
       "\n",
       "   carb  \n",
       "0     4  \n",
       "1     4  \n",
       "2     1  \n",
       "3     1  \n",
       "4     2  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>model</th>\n      <th>mpg</th>\n      <th>cyl</th>\n      <th>disp</th>\n      <th>hp</th>\n      <th>drat</th>\n      <th>wt</th>\n      <th>qsec</th>\n      <th>vs</th>\n      <th>am</th>\n      <th>gear</th>\n      <th>carb</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Mazda RX4</td>\n      <td>21.0</td>\n      <td>6</td>\n      <td>160.0</td>\n      <td>110</td>\n      <td>3.90</td>\n      <td>2.620</td>\n      <td>16.46</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Mazda RX4 Wag</td>\n      <td>21.0</td>\n      <td>6</td>\n      <td>160.0</td>\n      <td>110</td>\n      <td>3.90</td>\n      <td>2.875</td>\n      <td>17.02</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Datsun 710</td>\n      <td>22.8</td>\n      <td>4</td>\n      <td>108.0</td>\n      <td>93</td>\n      <td>3.85</td>\n      <td>2.320</td>\n      <td>18.61</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Hornet 4 Drive</td>\n      <td>21.4</td>\n      <td>6</td>\n      <td>258.0</td>\n      <td>110</td>\n      <td>3.08</td>\n      <td>3.215</td>\n      <td>19.44</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Hornet Sportabout</td>\n      <td>18.7</td>\n      <td>8</td>\n      <td>360.0</td>\n      <td>175</td>\n      <td>3.15</td>\n      <td>3.440</td>\n      <td>17.02</td>\n      <td>0</td>\n      <td>0</td>\n      <td>3</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "cars = pd.read_csv('../../inputs/mtcars.csv')\n",
    "cars.head()"
   ]
  },
  {
   "source": [
    "## Preparing your data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_prime = cars[['mpg','disp','hp','wt']].values\n",
    "y = cars.am.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = preprocessing.scale(x_prime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.2, random_state=17)"
   ]
  },
  {
   "source": [
    "## Building and training your model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "KNeighborsClassifier()\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "print(clf)"
   ]
  },
  {
   "source": [
    "## Evaluating your model predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.80      1.00      0.89         4\n           1       1.00      0.67      0.80         3\n\n    accuracy                           0.86         7\n   macro avg       0.90      0.83      0.84         7\nweighted avg       0.89      0.86      0.85         7\n\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(x_test)\n",
    "y_expect = y_test\n",
    "\n",
    "print(metrics.classification_report(y_expect, y_pred))"
   ]
  },
  {
   "source": [
    "These results are saying is that of all the points that were labeled one, only 67% of those results that were returned were truly relevant.\n",
    "And of the entire dataset, 83% of the results that were returned were truly relevant.\n",
    "\n",
    "High precision and low recall generally means that there are fewer results returned, but many of the labels that are predicted are returned correctly.\n",
    "In other words, high accuracy but low completion."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}